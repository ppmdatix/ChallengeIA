{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets import a some useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from tqdm import *\n",
    "import os \n",
    "import numpy as np \n",
    "from keras.preprocessing import image\n",
    "from keras.initializers import RandomNormal as RN\n",
    "from PIL import Image\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 128\n",
    "#img_width, img_height = size, size\n",
    "\n",
    "data_train_path_target = \"data_airbus_defi/train/\"\n",
    "data_test_path = \"data_airbus_defi/test/\"\n",
    "input_shape = (size, size, 3)\n",
    "#imput_shape = (size,size,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH = os.getcwd()\n",
    "full = True\n",
    "if full:\n",
    "    training_size = float(\"inf\")\n",
    "    testing_size = float(\"inf\")\n",
    "else:\n",
    "    training_size = 10\n",
    "    testing_size = 10\n",
    "    \n",
    "\n",
    "train_path = PATH +\"/\" + data_train_path_target + \"target/\"\n",
    "train_data_target = os.listdir(train_path)\n",
    "x_train = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#im_train = []\n",
    "tdt = 0\n",
    "for sample in (train_data_target):\n",
    "    img_path = train_path+sample\n",
    "    x = image.load_img(img_path)\n",
    "    # preprocessing if required\n",
    "    x_train.append(np.array(x))\n",
    "    \n",
    "    \"\"\"\n",
    "    im = Image.open(img_path)\n",
    "    im_grey = im.convert('L') # convert the image to *greyscale*\n",
    "    #im_bw = im_grey.point(lambda x: 0 if x<128 else 255, '1')\n",
    "    im_array = np.array(im_grey)\n",
    "    im_train.append(im_array)\n",
    "    \"\"\"\n",
    "    tdt += 1\n",
    "    \n",
    "    if tdt > training_size:\n",
    "        break\n",
    "\n",
    "train_path = PATH +\"/\" + data_train_path_target + \"other/\"\n",
    "train_data_other = os.listdir(train_path)\n",
    "x_train2 = []\n",
    "im_train2 = []\n",
    "tdo = 0\n",
    "for sample in (train_data_other):\n",
    "    img_path = train_path+sample\n",
    "    x = image.load_img(img_path)\n",
    "    # preprocessing if required\n",
    "    x_train2.append(np.array(x))\n",
    "    \"\"\"\n",
    "    im = Image.open(img_path)\n",
    "    im_grey = im.convert('L') # convert the image to *greyscale*\n",
    "    #im_bw = im_grey.point(lambda x: 0 if x<128 else 255, '1')\n",
    "    im_array = np.array(im_grey)\n",
    "    im_train2.append(im_array)\n",
    "    \"\"\"\n",
    "    tdo += 1\n",
    "    if tdo > training_size:\n",
    "        break\n",
    "\n",
    "    \n",
    "test_path = PATH+'/data_airbus_defi/test/'\n",
    "test_data = os.listdir(test_path)\n",
    "x_test = []\n",
    "#im_test = []\n",
    "\n",
    "\n",
    "td = 0\n",
    "for sample in (test_data):\n",
    "    img_path = test_path+sample\n",
    "    x = image.load_img(img_path)\n",
    "    # preprocessing if required\n",
    "    x_test.append(np.array(x))\n",
    "    \"\"\"\n",
    "    im = Image.open(img_path)\n",
    "    im_grey = im.convert('L') # convert the image to *greyscale*\n",
    "    #im_bw = im_grey.point(lambda x: 0 if x<128 else 255, '1')\n",
    "    im_array = np.array(im_grey)\n",
    "    im_test.append(im_array)\n",
    "    \"\"\"\n",
    "    td+=1\n",
    "    if td > testing_size:\n",
    "        break\n",
    "    \n",
    "    \n",
    "#test = np.array([np.array(x_t) for x_t in x_test])\n",
    "# finally converting list into numpy array\n",
    "x_train = np.array(x_train)\n",
    "x_train2 = np.array(x_train2)\n",
    "x_test = np.array(x_test) / 255.\n",
    "XTRAIN = np.concatenate((x_train, x_train2), axis=0) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32966, 128, 128, 3)\n",
      "(35252, 128, 128, 3)\n",
      "(68218, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_train2.shape)\n",
    "print(XTRAIN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#im_train = np.array(im_train)\n",
    "#im_train2 = np.array(im_train2)\n",
    "#IMTRAIN = np.concatenate((im_train, im_train2), axis=0).reshape((len(IMTRAIN),size,size,1)) / 255.\n",
    "#im_test = np.array(im_test).reshape((len(im_test),size,size,1)) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(im_train.shape)\n",
    "#print(im_train2.shape)\n",
    "#print(IMTRAIN.shape)\n",
    "#print(im_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = np.array([1] * x_train.shape[0] + [0] * x_train2.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "XTRAIN, train_labels = unison_shuffled_copies(XTRAIN,train_labels)\n",
    "#IMTRAIN, im_labels = unison_shuffled_copies(IMTRAIN,train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "# Plot training & validation accuracy values\n",
    "def plotModel(model):\n",
    "    SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "def plotLearning(history):\n",
    "    plt.plot(history.history['acc'])\n",
    "    #plt.plot(history.history['val_acc'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    #plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "def saveModel(model, name):\n",
    "    path = \"model/\" + name \n",
    "    model_json = model.to_json()\n",
    "    with open(path + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(path + \".h5\")\n",
    "    print(\"Saved model\")\n",
    "\n",
    "def loadModel(model, name):\n",
    "    path = \"model/\" + name \n",
    "    json_file = open(path + \".json\", 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(path + \".h5\")\n",
    "    return loaded_model\n",
    "    print(\"Loaded model from disk\")\n",
    "    \n",
    "\n",
    "    \n",
    "def soumissionCSV(prediction, name):\n",
    "    df_submission = pd.read_csv(\"data_airbus_defi/template_answer.csv\", sep=\";\")\n",
    "    df_submission[\"prediction\"] = prediction\n",
    "    df_submission = df_submission.set_index(\"name\")\n",
    "    df_submission.to_csv(name + \".csv\", sep=\";\")\n",
    "    print(\"CSV file written\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained = False\n",
    "\n",
    "epochs = 10\n",
    "validation_split = .1\n",
    "\n",
    "\n",
    "\n",
    "modelBW = Sequential()\n",
    "modelBW.add(Conv2D(12, (5), \n",
    "                  padding=\"same\", \n",
    "                  input_shape=input_shape))\n",
    "modelBW.add(Activation(\"relu\"))\n",
    "modelBW.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# second set of CONV => RELU => POOL layers\n",
    "modelBW.add(Conv2D(12, (5, 5), padding=\"same\"))\n",
    "modelBW.add(Activation(\"relu\"))\n",
    "modelBW.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "#first (and only) set of FC => RELU layers\n",
    "modelBW.add(Flatten())\n",
    "modelBW.add(Dense(2))\n",
    "modelBW.add(Activation(\"sigmoid\"))\n",
    "\n",
    "# softmax classifier\n",
    "modelBW.add(Dense(1))\n",
    "modelBW.add(Activation(\"relu\"))\n",
    "\n",
    "\n",
    "if trained:\n",
    "    modelBW.load_weights('model/modelSMALL.h5')\n",
    "modelBW.compile(loss='mse',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "if not trained:\n",
    "    history = modelBW.fit(XTRAIN, train_labels,\n",
    "            epochs=epochs, verbose=1, validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = modelBW.predict(x_test)\n",
    "def cut_half(x):\n",
    "    if x < .5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "prediction = [cut_half(x) for x in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soumissionCSV(prediction, \"1erNovembre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import system\n",
    "system('say On est bon!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7201 samples, validate on 801 samples\n",
      "Epoch 1/4\n",
      "7201/7201 [==============================] - 226s 31ms/step - loss: 0.3956 - acc: 0.4958 - val_loss: 0.2504 - val_acc: 0.5069\n",
      "Epoch 2/4\n",
      "7201/7201 [==============================] - 229s 32ms/step - loss: 0.2648 - acc: 0.4967 - val_loss: 0.2495 - val_acc: 0.5094\n",
      "Epoch 3/4\n",
      "7201/7201 [==============================] - 251s 35ms/step - loss: 0.2493 - acc: 0.5101 - val_loss: 0.2499 - val_acc: 0.5094\n",
      "Epoch 4/4\n",
      "7201/7201 [==============================] - 234s 33ms/step - loss: 0.2494 - acc: 0.5052 - val_loss: 0.2565 - val_acc: 0.5094\n"
     ]
    }
   ],
   "source": [
    "trained = True\n",
    "\n",
    "modelSMALL = Sequential()\n",
    "inputShape = (size, size, 3)\n",
    "modelSMALL.add(Conv2D(20, (5, 5), \n",
    "                  padding=\"same\", \n",
    "                  input_shape=inputShape,\n",
    "                  kernel_initializer=RN(0,1)))\n",
    "modelSMALL.add(Activation(\"relu\"))\n",
    "modelSMALL.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# second set of CONV => RELU => POOL layers\n",
    "modelSMALL.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
    "modelSMALL.add(Activation(\"relu\"))\n",
    "modelSMALL.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# first (and only) set of FC => RELU layers\n",
    "modelSMALL.add(Flatten())\n",
    "modelSMALL.add(Dense(32))\n",
    "modelSMALL.add(Activation(\"sigmoid\"))\n",
    "\n",
    "# softmax classifier\n",
    "modelSMALL.add(Dense(1))\n",
    "modelSMALL.add(Activation(\"relu\"))\n",
    "if trained:\n",
    "    modelSMALL.load_weights('model/modelSMALL.h5')\n",
    "modelSMALL.compile(loss='mse',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "if not trained:\n",
    "    history = modelSMALL.fit(\n",
    "            XTRAIN, train_labels,\n",
    "            epochs=4, verbose=1, validation_split = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelSMALL.save_weights('model/modelSMALL.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = modelSMALL.predict(x_test)\n",
    "prediction = [float(x) for x in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5931853],\n",
       "       [0.5931853],\n",
       "       [0.5931853],\n",
       "       ...,\n",
       "       [0.5931853],\n",
       "       [0.5931853],\n",
       "       [0.5931853]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cut_half(x):\n",
    "    if x < .5:\n",
    "        return 0.\n",
    "    else:\n",
    "        return 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = [cut_half(x) for x in prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17026.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17027.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17028.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17029.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17030.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17031.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17032.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17033.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17034.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17035.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17036.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17037.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17038.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17039.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17040.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17041.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17042.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17043.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17044.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17045.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17046.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17047.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17048.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17049.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17050.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17051.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17052.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17053.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17054.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17055.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17056 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           prediction\n",
       "name                 \n",
       "0.jpg               1\n",
       "1.jpg               0\n",
       "2.jpg               1\n",
       "3.jpg               1\n",
       "4.jpg               1\n",
       "5.jpg               1\n",
       "6.jpg               1\n",
       "7.jpg               0\n",
       "8.jpg               1\n",
       "9.jpg               1\n",
       "10.jpg              1\n",
       "11.jpg              0\n",
       "12.jpg              1\n",
       "13.jpg              1\n",
       "14.jpg              0\n",
       "15.jpg              0\n",
       "16.jpg              0\n",
       "17.jpg              1\n",
       "18.jpg              0\n",
       "19.jpg              0\n",
       "20.jpg              0\n",
       "21.jpg              0\n",
       "22.jpg              1\n",
       "23.jpg              0\n",
       "24.jpg              0\n",
       "25.jpg              1\n",
       "26.jpg              0\n",
       "27.jpg              1\n",
       "28.jpg              1\n",
       "29.jpg              1\n",
       "...               ...\n",
       "17026.jpg           1\n",
       "17027.jpg           0\n",
       "17028.jpg           1\n",
       "17029.jpg           0\n",
       "17030.jpg           1\n",
       "17031.jpg           1\n",
       "17032.jpg           1\n",
       "17033.jpg           0\n",
       "17034.jpg           1\n",
       "17035.jpg           0\n",
       "17036.jpg           1\n",
       "17037.jpg           0\n",
       "17038.jpg           0\n",
       "17039.jpg           0\n",
       "17040.jpg           1\n",
       "17041.jpg           1\n",
       "17042.jpg           1\n",
       "17043.jpg           1\n",
       "17044.jpg           1\n",
       "17045.jpg           1\n",
       "17046.jpg           0\n",
       "17047.jpg           0\n",
       "17048.jpg           1\n",
       "17049.jpg           0\n",
       "17050.jpg           0\n",
       "17051.jpg           1\n",
       "17052.jpg           1\n",
       "17053.jpg           0\n",
       "17054.jpg           0\n",
       "17055.jpg           1\n",
       "\n",
       "[17056 rows x 1 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17056, 128, 128, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_size = 16\n",
    "pool_size = (3,3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(conv_size, \n",
    "                 (3, 3), \n",
    "                 input_shape=input_shape, \n",
    "                 kernel_initializer=RN(0,1)))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "model.add(Conv2D(conv_size, (3, 3), kernel_initializer=RN(1,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "model.add(Conv2D(conv_size, (3, 3),kernel_initializer=RN(1,1)))\n",
    "\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "251/250 [==============================] - 65s 260ms/step - loss: 0.2631 - acc: 0.5061\n",
      "Epoch 2/12\n",
      "251/250 [==============================] - 68s 273ms/step - loss: 0.2525 - acc: 0.4958\n",
      "Epoch 3/12\n",
      "251/250 [==============================] - 64s 255ms/step - loss: 0.2505 - acc: 0.4960\n",
      "Epoch 4/12\n",
      "251/250 [==============================] - 64s 256ms/step - loss: 0.2501 - acc: 0.5077\n",
      "Epoch 5/12\n",
      "251/250 [==============================] - 66s 261ms/step - loss: 0.2504 - acc: 0.4839\n",
      "Epoch 6/12\n",
      "251/250 [==============================] - 64s 253ms/step - loss: 0.2502 - acc: 0.5030\n",
      "Epoch 7/12\n",
      "159/250 [==================>...........] - ETA: 24s - loss: 0.2502 - acc: 0.5014"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-5d9f8899b160>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# fits the model on batches with real-time data augmentation:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m history = model.fit_generator(datagen.flow(XTRAIN, train_labels, batch_size=32),\n\u001b[0;32m---> 19\u001b[0;31m                     steps_per_epoch=len(XTRAIN) / 32, epochs=epochs, verbose=1)\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# here's a more \"manual\" example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ppx/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ppx/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1274\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ppx/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ppx/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2224\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ppx/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ppx/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ppx/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ppx/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ppx/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ppx/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ppx/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ppx/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(XTRAIN)\n",
    "epochs = 12\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "history = model.fit_generator(datagen.flow(XTRAIN, train_labels, batch_size=32),\n",
    "                    steps_per_epoch=len(XTRAIN) / 32, epochs=epochs, verbose=1)\n",
    "\n",
    "# here's a more \"manual\" example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for e in range(epochs):\n",
    "    print('Epoch', e)\n",
    "    batches = 0\n",
    "    for x_batch, y_batch in datagen.flow(XTRAIN, label, batch_size=32):\n",
    "        model.fit(x_batch, y_batch)\n",
    "        batches += 1\n",
    "        if batches >= len(x_train) / 32:\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = modelSMALL.predict(x_test[:10])\n",
    "prediction = [float(x) for x in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.593185305595398,\n",
       " 0.593185305595398,\n",
       " 0.593185305595398,\n",
       " 0.593185305595398,\n",
       " 0.593185305595398,\n",
       " 0.593185305595398,\n",
       " 0.593185305595398,\n",
       " 0.593185305595398,\n",
       " 0.593185305595398,\n",
       " 0.593185305595398]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.28627451, 0.29411765, 0.21176471],\n",
       "         [0.32941176, 0.3372549 , 0.25490196],\n",
       "         [0.38823529, 0.39607843, 0.31372549],\n",
       "         ...,\n",
       "         [0.16078431, 0.22352941, 0.18039216],\n",
       "         [0.12941176, 0.19215686, 0.14901961],\n",
       "         [0.10588235, 0.16862745, 0.1254902 ]],\n",
       "\n",
       "        [[0.2627451 , 0.27058824, 0.18431373],\n",
       "         [0.29803922, 0.30588235, 0.21960784],\n",
       "         [0.34901961, 0.35686275, 0.2745098 ],\n",
       "         ...,\n",
       "         [0.16078431, 0.22352941, 0.18039216],\n",
       "         [0.13333333, 0.19607843, 0.15294118],\n",
       "         [0.10980392, 0.17254902, 0.12941176]],\n",
       "\n",
       "        [[0.26666667, 0.2627451 , 0.18039216],\n",
       "         [0.29019608, 0.28627451, 0.20392157],\n",
       "         [0.32941176, 0.3254902 , 0.24313725],\n",
       "         ...,\n",
       "         [0.15686275, 0.21960784, 0.16862745],\n",
       "         [0.13333333, 0.19607843, 0.14509804],\n",
       "         [0.11372549, 0.17647059, 0.1254902 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.29411765, 0.26666667, 0.15294118],\n",
       "         [0.29019608, 0.2627451 , 0.14901961],\n",
       "         [0.28235294, 0.25490196, 0.14117647],\n",
       "         ...,\n",
       "         [0.05490196, 0.12156863, 0.04705882],\n",
       "         [0.08627451, 0.14509804, 0.07058824],\n",
       "         [0.09019608, 0.14901961, 0.06666667]],\n",
       "\n",
       "        [[0.32156863, 0.29411765, 0.18039216],\n",
       "         [0.30588235, 0.27843137, 0.16470588],\n",
       "         [0.29411765, 0.26666667, 0.15294118],\n",
       "         ...,\n",
       "         [0.09411765, 0.16078431, 0.08627451],\n",
       "         [0.12941176, 0.18823529, 0.11372549],\n",
       "         [0.12941176, 0.18823529, 0.10588235]],\n",
       "\n",
       "        [[0.34901961, 0.32156863, 0.20784314],\n",
       "         [0.3254902 , 0.29803922, 0.18431373],\n",
       "         [0.30196078, 0.2745098 , 0.16078431],\n",
       "         ...,\n",
       "         [0.09411765, 0.16078431, 0.08627451],\n",
       "         [0.13333333, 0.19215686, 0.11764706],\n",
       "         [0.12941176, 0.18823529, 0.10588235]]],\n",
       "\n",
       "\n",
       "       [[[0.27843137, 0.26666667, 0.2       ],\n",
       "         [0.49411765, 0.48235294, 0.41568627],\n",
       "         [0.53333333, 0.50980392, 0.44705882],\n",
       "         ...,\n",
       "         [0.99215686, 0.99215686, 0.98431373],\n",
       "         [0.99215686, 0.99215686, 0.98431373],\n",
       "         [0.99215686, 0.99215686, 0.98431373]],\n",
       "\n",
       "        [[0.29803922, 0.28627451, 0.21960784],\n",
       "         [0.47843137, 0.46666667, 0.4       ],\n",
       "         [0.52941176, 0.50588235, 0.44313725],\n",
       "         ...,\n",
       "         [0.99215686, 0.99215686, 0.98431373],\n",
       "         [0.99215686, 0.99215686, 0.98431373],\n",
       "         [0.99215686, 0.99215686, 0.98431373]],\n",
       "\n",
       "        [[0.62352941, 0.61176471, 0.5372549 ],\n",
       "         [0.63529412, 0.62352941, 0.54901961],\n",
       "         [0.54901961, 0.5254902 , 0.4627451 ],\n",
       "         ...,\n",
       "         [0.99215686, 0.99215686, 0.98431373],\n",
       "         [0.99215686, 0.99215686, 0.98431373],\n",
       "         [0.99215686, 0.99215686, 0.98431373]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.64705882, 0.65098039, 0.59607843],\n",
       "         [0.57254902, 0.56470588, 0.50588235],\n",
       "         [0.5372549 , 0.52941176, 0.47058824],\n",
       "         ...,\n",
       "         [0.40392157, 0.37647059, 0.31372549],\n",
       "         [0.34117647, 0.31372549, 0.25098039],\n",
       "         [0.35686275, 0.32941176, 0.26666667]],\n",
       "\n",
       "        [[0.61960784, 0.62352941, 0.56862745],\n",
       "         [0.60392157, 0.59607843, 0.5372549 ],\n",
       "         [0.56862745, 0.56078431, 0.50196078],\n",
       "         ...,\n",
       "         [0.38431373, 0.35686275, 0.29411765],\n",
       "         [0.32941176, 0.30196078, 0.23921569],\n",
       "         [0.38039216, 0.35294118, 0.29019608]],\n",
       "\n",
       "        [[0.58039216, 0.58431373, 0.52941176],\n",
       "         [0.64313725, 0.63529412, 0.57647059],\n",
       "         [0.59215686, 0.58431373, 0.5254902 ],\n",
       "         ...,\n",
       "         [0.36862745, 0.34117647, 0.27843137],\n",
       "         [0.31764706, 0.29019608, 0.22745098],\n",
       "         [0.40784314, 0.38039216, 0.31764706]]],\n",
       "\n",
       "\n",
       "       [[[0.26666667, 0.37647059, 0.18431373],\n",
       "         [0.27058824, 0.38039216, 0.18823529],\n",
       "         [0.2745098 , 0.38431373, 0.19215686],\n",
       "         ...,\n",
       "         [0.2627451 , 0.37647059, 0.18823529],\n",
       "         [0.27058824, 0.38431373, 0.19607843],\n",
       "         [0.2745098 , 0.38823529, 0.2       ]],\n",
       "\n",
       "        [[0.29019608, 0.4       , 0.20784314],\n",
       "         [0.29019608, 0.4       , 0.20784314],\n",
       "         [0.29411765, 0.40392157, 0.21176471],\n",
       "         ...,\n",
       "         [0.27058824, 0.38431373, 0.19607843],\n",
       "         [0.27843137, 0.39215686, 0.20392157],\n",
       "         [0.28235294, 0.39607843, 0.20784314]],\n",
       "\n",
       "        [[0.30196078, 0.41176471, 0.21960784],\n",
       "         [0.29803922, 0.40784314, 0.21568627],\n",
       "         [0.29803922, 0.40784314, 0.21568627],\n",
       "         ...,\n",
       "         [0.28627451, 0.39607843, 0.20784314],\n",
       "         [0.29411765, 0.40392157, 0.21568627],\n",
       "         [0.29803922, 0.40784314, 0.21960784]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.4       , 0.37254902, 0.25882353],\n",
       "         [0.38039216, 0.35294118, 0.24313725],\n",
       "         [0.38039216, 0.35294118, 0.24313725],\n",
       "         ...,\n",
       "         [0.31372549, 0.29803922, 0.18431373],\n",
       "         [0.30980392, 0.29411765, 0.18039216],\n",
       "         [0.30980392, 0.29411765, 0.18039216]],\n",
       "\n",
       "        [[0.40784314, 0.38039216, 0.26666667],\n",
       "         [0.39215686, 0.36470588, 0.25490196],\n",
       "         [0.38823529, 0.36078431, 0.25098039],\n",
       "         ...,\n",
       "         [0.30196078, 0.28627451, 0.17254902],\n",
       "         [0.30588235, 0.29019608, 0.17647059],\n",
       "         [0.30980392, 0.29411765, 0.18039216]],\n",
       "\n",
       "        [[0.41176471, 0.38431373, 0.27058824],\n",
       "         [0.39607843, 0.36862745, 0.25882353],\n",
       "         [0.39607843, 0.36862745, 0.25882353],\n",
       "         ...,\n",
       "         [0.29411765, 0.27843137, 0.16470588],\n",
       "         [0.30196078, 0.28627451, 0.17254902],\n",
       "         [0.30980392, 0.29411765, 0.18039216]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.14117647, 0.22745098, 0.14509804],\n",
       "         [0.11764706, 0.20392157, 0.12156863],\n",
       "         [0.1254902 , 0.21176471, 0.12941176],\n",
       "         ...,\n",
       "         [0.01568627, 0.10980392, 0.10980392],\n",
       "         [0.01568627, 0.10980392, 0.10980392],\n",
       "         [0.01568627, 0.10980392, 0.10980392]],\n",
       "\n",
       "        [[0.17254902, 0.25882353, 0.17647059],\n",
       "         [0.15294118, 0.23921569, 0.15686275],\n",
       "         [0.16078431, 0.24705882, 0.16470588],\n",
       "         ...,\n",
       "         [0.01960784, 0.11372549, 0.11372549],\n",
       "         [0.01960784, 0.11372549, 0.11372549],\n",
       "         [0.01960784, 0.11372549, 0.11372549]],\n",
       "\n",
       "        [[0.09803922, 0.18431373, 0.10196078],\n",
       "         [0.09019608, 0.17647059, 0.09411765],\n",
       "         [0.11764706, 0.20392157, 0.12156863],\n",
       "         ...,\n",
       "         [0.01568627, 0.10980392, 0.10980392],\n",
       "         [0.01568627, 0.10980392, 0.10980392],\n",
       "         [0.01568627, 0.10980392, 0.10980392]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.02745098, 0.14117647, 0.12156863],\n",
       "         [0.02745098, 0.14117647, 0.12156863],\n",
       "         [0.02745098, 0.14117647, 0.12156863],\n",
       "         ...,\n",
       "         [0.50588235, 0.41568627, 0.29411765],\n",
       "         [0.50588235, 0.41568627, 0.29411765],\n",
       "         [0.50588235, 0.41568627, 0.29411765]],\n",
       "\n",
       "        [[0.03529412, 0.14901961, 0.12941176],\n",
       "         [0.03529412, 0.14901961, 0.12941176],\n",
       "         [0.03529412, 0.14901961, 0.12941176],\n",
       "         ...,\n",
       "         [0.50196078, 0.41176471, 0.29019608],\n",
       "         [0.50196078, 0.41176471, 0.29019608],\n",
       "         [0.50196078, 0.41176471, 0.29019608]],\n",
       "\n",
       "        [[0.03529412, 0.14901961, 0.12941176],\n",
       "         [0.03921569, 0.15294118, 0.13333333],\n",
       "         [0.03921569, 0.15294118, 0.13333333],\n",
       "         ...,\n",
       "         [0.50196078, 0.41176471, 0.29019608],\n",
       "         [0.50196078, 0.41176471, 0.29019608],\n",
       "         [0.50196078, 0.41176471, 0.29019608]]],\n",
       "\n",
       "\n",
       "       [[[0.77647059, 0.65882353, 0.50980392],\n",
       "         [0.78039216, 0.6627451 , 0.51372549],\n",
       "         [0.78823529, 0.67058824, 0.52156863],\n",
       "         ...,\n",
       "         [0.71764706, 0.59215686, 0.44313725],\n",
       "         [0.72156863, 0.59607843, 0.44705882],\n",
       "         [0.72941176, 0.60392157, 0.45490196]],\n",
       "\n",
       "        [[0.77647059, 0.65882353, 0.50980392],\n",
       "         [0.78039216, 0.6627451 , 0.51372549],\n",
       "         [0.78431373, 0.66666667, 0.51764706],\n",
       "         ...,\n",
       "         [0.7254902 , 0.6       , 0.45098039],\n",
       "         [0.72941176, 0.60392157, 0.45490196],\n",
       "         [0.7372549 , 0.61176471, 0.4627451 ]],\n",
       "\n",
       "        [[0.77254902, 0.65490196, 0.50588235],\n",
       "         [0.77647059, 0.65882353, 0.50980392],\n",
       "         [0.77647059, 0.65882353, 0.50980392],\n",
       "         ...,\n",
       "         [0.74117647, 0.61568627, 0.46666667],\n",
       "         [0.74117647, 0.61568627, 0.46666667],\n",
       "         [0.74509804, 0.61960784, 0.47058824]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.82352941, 0.70980392, 0.57647059],\n",
       "         [0.82352941, 0.70980392, 0.57647059],\n",
       "         [0.82352941, 0.70980392, 0.57647059],\n",
       "         ...,\n",
       "         [0.76078431, 0.64313725, 0.50980392],\n",
       "         [0.76078431, 0.64313725, 0.50980392],\n",
       "         [0.76470588, 0.64705882, 0.51372549]],\n",
       "\n",
       "        [[0.82745098, 0.71372549, 0.58039216],\n",
       "         [0.82352941, 0.70980392, 0.57647059],\n",
       "         [0.82352941, 0.70980392, 0.57647059],\n",
       "         ...,\n",
       "         [0.76078431, 0.64313725, 0.50980392],\n",
       "         [0.76078431, 0.64313725, 0.50980392],\n",
       "         [0.76470588, 0.64705882, 0.51372549]],\n",
       "\n",
       "        [[0.82352941, 0.70980392, 0.57647059],\n",
       "         [0.82352941, 0.70980392, 0.57647059],\n",
       "         [0.81960784, 0.70588235, 0.57254902],\n",
       "         ...,\n",
       "         [0.75686275, 0.63921569, 0.50588235],\n",
       "         [0.76470588, 0.64705882, 0.51372549],\n",
       "         [0.76470588, 0.64705882, 0.51372549]]],\n",
       "\n",
       "\n",
       "       [[[0.38039216, 0.3254902 , 0.21176471],\n",
       "         [0.40784314, 0.34901961, 0.23529412],\n",
       "         [0.42745098, 0.36078431, 0.25882353],\n",
       "         ...,\n",
       "         [0.4627451 , 0.35294118, 0.29803922],\n",
       "         [0.4745098 , 0.36470588, 0.30980392],\n",
       "         [0.48627451, 0.37647059, 0.32156863]],\n",
       "\n",
       "        [[0.37647059, 0.32156863, 0.20784314],\n",
       "         [0.39215686, 0.33333333, 0.21960784],\n",
       "         [0.4       , 0.33333333, 0.23137255],\n",
       "         ...,\n",
       "         [0.45882353, 0.34901961, 0.29411765],\n",
       "         [0.4745098 , 0.36470588, 0.30980392],\n",
       "         [0.48235294, 0.37254902, 0.31764706]],\n",
       "\n",
       "        [[0.34509804, 0.28235294, 0.18039216],\n",
       "         [0.34509804, 0.28235294, 0.18039216],\n",
       "         [0.3372549 , 0.27058824, 0.16862745],\n",
       "         ...,\n",
       "         [0.45098039, 0.34509804, 0.27843137],\n",
       "         [0.46666667, 0.36078431, 0.29411765],\n",
       "         [0.47843137, 0.37254902, 0.30588235]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.37254902, 0.25882353, 0.18823529],\n",
       "         [0.36862745, 0.25490196, 0.18431373],\n",
       "         [0.36470588, 0.25098039, 0.18039216],\n",
       "         ...,\n",
       "         [0.37254902, 0.28627451, 0.19215686],\n",
       "         [0.36470588, 0.27843137, 0.18431373],\n",
       "         [0.36470588, 0.27843137, 0.18431373]],\n",
       "\n",
       "        [[0.41568627, 0.30196078, 0.23137255],\n",
       "         [0.41568627, 0.30196078, 0.23137255],\n",
       "         [0.41176471, 0.29803922, 0.22745098],\n",
       "         ...,\n",
       "         [0.4       , 0.30588235, 0.20392157],\n",
       "         [0.38823529, 0.29411765, 0.19215686],\n",
       "         [0.37647059, 0.28235294, 0.18039216]],\n",
       "\n",
       "        [[0.44313725, 0.32941176, 0.26666667],\n",
       "         [0.44705882, 0.33333333, 0.27058824],\n",
       "         [0.44313725, 0.32941176, 0.26666667],\n",
       "         ...,\n",
       "         [0.36078431, 0.26666667, 0.15686275],\n",
       "         [0.34117647, 0.24705882, 0.1372549 ],\n",
       "         [0.3254902 , 0.23137255, 0.12156863]]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ppx/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 68218 images belonging to 2 classes.\n",
      "Found 68218 images belonging to 2 classes.\n",
      "Epoch 1/2\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7073 - acc: 0.3750\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.8141 - acc: 0.6250\n"
     ]
    }
   ],
   "source": [
    "rescale_factor = 255\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / rescale_factor,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / rescale_factor)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(size, size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(size, size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs)#,\n",
    "    #validation_data=validation_generator,\n",
    "    #validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train_path_target = \"data_airbus_defi/train/\"\n",
    "data_test_path = \"data_airbus_defi/test\"\n",
    "size = 128\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 68218 images belonging to 2 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator()\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        data_train_path_target,\n",
    "        target_size=(size, size),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        data_test_path,\n",
    "        target_size=(128, 128),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelSMALL = Sequential()\n",
    "inputShape = (size, size, 3)\n",
    "modelSMALL.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=inputShape))\n",
    "modelSMALL.add(Activation(\"relu\"))\n",
    "modelSMALL.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# second set of CONV => RELU => POOL layers\n",
    "modelSMALL.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
    "modelSMALL.add(Activation(\"relu\"))\n",
    "modelSMALL.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# first (and only) set of FC => RELU layers\n",
    "modelSMALL.add(Flatten())\n",
    "modelSMALL.add(Dense(500))\n",
    "modelSMALL.add(Activation(\"relu\"))\n",
    "\n",
    "# softmax classifier\n",
    "modelSMALL.add(Dense(1))\n",
    "modelSMALL.add(Activation(\"softmax\"))\n",
    "\n",
    "\n",
    "modelSMALL.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = modelSMALL.fit(\n",
    "        XTRAIN, train_labels,\n",
    "        steps_per_epoch=2000,\n",
    "        epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = modelSMALL.fit(\n",
    "        XTRAIN, train_labels,\n",
    "        steps_per_epoch=2000,\n",
    "        epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
